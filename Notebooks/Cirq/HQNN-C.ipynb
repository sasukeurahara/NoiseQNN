{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1805693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "import time\n",
    "import sympy\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad25a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "n_qubits = 2\n",
    "noise_type = \"depolarizing\"  # Change to \"bitflip\", \"phaseflip\", \"amplitude_damping\"\n",
    "noise_strength = 0.05\n",
    "\n",
    "# Data preparation\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :n_qubits]  # only first n_qubits features\n",
    "y = iris.target\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensor\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float64)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float64)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float64)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float64)\n",
    "\n",
    "# Create qubits\n",
    "qubits = [cirq.GridQubit(0, i) for i in range(n_qubits)]\n",
    "\n",
    "class CirqQuantumLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A PyTorch layer that wraps a Cirq quantum circuit\n",
    "    \"\"\"\n",
    "    def __init__(self, n_qubits, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.qubits = [cirq.GridQubit(0, i) for i in range(n_qubits)]\n",
    "        \n",
    "        # Initialize quantum parameters as PyTorch parameters\n",
    "        # Shape: (n_layers, n_qubits, 3) for strongly entangling layers\n",
    "        self.quantum_weights = torch.nn.Parameter(\n",
    "            torch.randn(n_layers, n_qubits, 3, dtype=torch.float64) * 0.5\n",
    "        )\n",
    "        \n",
    "        # Use density matrix simulator for noise\n",
    "        self.simulator = cirq.DensityMatrixSimulator()\n",
    "        \n",
    "    def add_noise_layer(self, circuit):\n",
    "        \"\"\"Add noise to all qubits according to noise_type\"\"\"\n",
    "        if noise_type == \"depolarizing\":\n",
    "            for qubit in self.qubits:\n",
    "                circuit.append(cirq.depolarize(noise_strength)(qubit))\n",
    "        elif noise_type == \"bitflip\":\n",
    "            for qubit in self.qubits:\n",
    "                circuit.append(cirq.bit_flip(noise_strength)(qubit))\n",
    "        elif noise_type == \"phaseflip\":\n",
    "            for qubit in self.qubits:\n",
    "                circuit.append(cirq.phase_flip(noise_strength)(qubit))\n",
    "        elif noise_type == \"amplitude_damping\":\n",
    "            for qubit in self.qubits:\n",
    "                circuit.append(cirq.amplitude_damp(noise_strength)(qubit))\n",
    "    \n",
    "    def angle_embedding(self, circuit, inputs):\n",
    "        \"\"\"Embed classical data as rotation angles\"\"\"\n",
    "        # Convert tensor to numpy if needed\n",
    "        if isinstance(inputs, torch.Tensor):\n",
    "            inputs = inputs.detach().cpu().numpy()\n",
    "        for i, qubit in enumerate(self.qubits):\n",
    "            circuit.append(cirq.ry(float(inputs[i]))(qubit))\n",
    "    \n",
    "    def strongly_entangling_layer(self, circuit, weights, layer_idx):\n",
    "        \"\"\"Implement strongly entangling layer\"\"\"\n",
    "        # Convert tensor to numpy if needed\n",
    "        if isinstance(weights, torch.Tensor):\n",
    "            weights = weights.detach().cpu().numpy()\n",
    "            \n",
    "        # Apply rotations\n",
    "        for i, qubit in enumerate(self.qubits):\n",
    "            circuit.append(cirq.rx(float(weights[layer_idx, i, 0]))(qubit))\n",
    "            circuit.append(cirq.ry(float(weights[layer_idx, i, 1]))(qubit))\n",
    "            circuit.append(cirq.rz(float(weights[layer_idx, i, 2]))(qubit))\n",
    "        \n",
    "        # Add entangling gates\n",
    "        for i in range(self.n_qubits):\n",
    "            control = self.qubits[i]\n",
    "            target = self.qubits[(i + 1) % self.n_qubits]\n",
    "            circuit.append(cirq.CNOT(control, target))\n",
    "    \n",
    "    def create_circuit(self, inputs, weights):\n",
    "        \"\"\"Create the complete quantum circuit\"\"\"\n",
    "        circuit = cirq.Circuit()\n",
    "        \n",
    "        # Angle embedding\n",
    "        self.angle_embedding(circuit, inputs)\n",
    "        \n",
    "        # Add noise after embedding\n",
    "        self.add_noise_layer(circuit)\n",
    "        \n",
    "        # Strongly entangling layers\n",
    "        for layer in range(self.n_layers):\n",
    "            self.strongly_entangling_layer(circuit, weights, layer)\n",
    "        \n",
    "        # Add noise after ansatz\n",
    "        self.add_noise_layer(circuit)\n",
    "        \n",
    "        return circuit\n",
    "    \n",
    "    def get_expectation_values(self, circuit):\n",
    "        \"\"\"Calculate expectation values of Pauli-Z on all qubits\"\"\"\n",
    "        result = self.simulator.simulate(circuit)\n",
    "        expectations = []\n",
    "        \n",
    "        for i, qubit in enumerate(self.qubits):\n",
    "            z_op = cirq.Z(qubit)\n",
    "            expectation = z_op.expectation_from_density_matrix(\n",
    "                result.final_density_matrix,\n",
    "                qubit_map={q: j for j, q in enumerate(self.qubits)}\n",
    "            ).real\n",
    "            expectations.append(expectation)\n",
    "        \n",
    "        return torch.tensor(expectations, dtype=torch.float64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the quantum layer\"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Convert input to numpy for Cirq\n",
    "            x_numpy = x[i].detach().cpu().numpy()\n",
    "            weights_numpy = self.quantum_weights.detach().cpu().numpy()\n",
    "            \n",
    "            # Create circuit for this input\n",
    "            circuit = self.create_circuit(x_numpy, weights_numpy)\n",
    "            \n",
    "            # Get expectation values\n",
    "            expectations = self.get_expectation_values(circuit)\n",
    "            outputs.append(expectations)\n",
    "        \n",
    "        return torch.stack(outputs)\n",
    "\n",
    "class CirqQuantumLayerDifferentiable(CirqQuantumLayer):\n",
    "    \"\"\"\n",
    "    Differentiable version using finite differences for gradients\n",
    "    \"\"\"\n",
    "    def __init__(self, n_qubits, n_layers=1, epsilon=0.01):\n",
    "        super().__init__(n_qubits, n_layers)\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define a function that computes the quantum circuit output\n",
    "        def quantum_function(weights_flat, x_input):\n",
    "            weights_reshaped = weights_flat.view(self.n_layers, self.n_qubits, 3)\n",
    "            # Convert tensors to numpy for Cirq\n",
    "            x_numpy = x_input.detach().cpu().numpy() if isinstance(x_input, torch.Tensor) else x_input\n",
    "            weights_numpy = weights_reshaped.detach().cpu().numpy()\n",
    "            circuit = self.create_circuit(x_numpy, weights_numpy)\n",
    "            expectations = self.get_expectation_values(circuit)\n",
    "            return expectations\n",
    "        \n",
    "        # Enable gradients using autograd.Function\n",
    "        return QuantumFunction.apply(quantum_function, self.quantum_weights.flatten(), x, self.quantum_weights.shape)\n",
    "\n",
    "class QuantumFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, quantum_func, weights_flat, x, weight_shape):\n",
    "        ctx.quantum_func = quantum_func\n",
    "        ctx.weight_shape = weight_shape\n",
    "        ctx.save_for_backward(weights_flat, x)\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Convert to numpy for Cirq\n",
    "            x_numpy = x[i].detach().cpu().numpy() if isinstance(x[i], torch.Tensor) else x[i]\n",
    "            output = quantum_func(weights_flat, x_numpy)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        return torch.stack(outputs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        quantum_func = ctx.quantum_func\n",
    "        weights_flat, x = ctx.saved_tensors\n",
    "        weight_shape = ctx.weight_shape\n",
    "        \n",
    "        # Finite difference for gradients\n",
    "        epsilon = 0.01\n",
    "        grad_weights = torch.zeros_like(weights_flat)\n",
    "        \n",
    "        # Only compute gradients for weights (not for x)\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        for param_idx in range(len(weights_flat)):\n",
    "            # Forward difference\n",
    "            weights_plus = weights_flat.clone()\n",
    "            weights_plus[param_idx] += epsilon\n",
    "            \n",
    "            weights_minus = weights_flat.clone()\n",
    "            weights_minus[param_idx] -= epsilon\n",
    "            \n",
    "            outputs_plus = []\n",
    "            outputs_minus = []\n",
    "            \n",
    "            for batch_idx in range(batch_size):\n",
    "                # Convert to numpy for Cirq\n",
    "                x_numpy = x[batch_idx].detach().cpu().numpy()\n",
    "                out_plus = quantum_func(weights_plus, x_numpy)\n",
    "                out_minus = quantum_func(weights_minus, x_numpy)\n",
    "                outputs_plus.append(out_plus)\n",
    "                outputs_minus.append(out_minus)\n",
    "            \n",
    "            outputs_plus = torch.stack(outputs_plus)\n",
    "            outputs_minus = torch.stack(outputs_minus)\n",
    "            \n",
    "            # Finite difference gradient\n",
    "            finite_diff = (outputs_plus - outputs_minus) / (2 * epsilon)\n",
    "            \n",
    "            # Apply chain rule\n",
    "            grad_weights[param_idx] = torch.sum(grad_output * finite_diff)\n",
    "        \n",
    "        return None, grad_weights, None, None\n",
    "\n",
    "class HQNN(nn.Module):\n",
    "    \"\"\"Hybrid Quantum Neural Network with Cirq backend\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quantum_layer = CirqQuantumLayerDifferentiable(n_qubits, n_layers=1)\n",
    "        self.classical_layer = nn.Linear(n_qubits, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        quantum_output = self.quantum_layer(x)\n",
    "        return self.classical_layer(quantum_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28fdfcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 5/30, Loss: 0.585217\n",
      "Epoch 10/30, Loss: 0.559069\n",
      "Epoch 15/30, Loss: 0.542188\n",
      "Epoch 20/30, Loss: 0.529044\n",
      "Epoch 25/30, Loss: 0.517563\n",
      "Epoch 30/30, Loss: 0.507608\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = HQNN()\n",
    "model = model.to(dtype=torch.float64)\n",
    "\n",
    "# Training\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "epochs = 30\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    preds = model(X_train)\n",
    "    loss = loss_fn(preds.squeeze(), y_train)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}\")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06308352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "Noise type       : depolarizing\n",
      "Noise strength   : 0.05\n",
      "Number of qubits : 2\n",
      "MSE              : 0.618277\n",
      "RMSE             : 0.786306\n",
      "MAE              : 0.686132\n",
      "F1-score         : 0.269231\n",
      "epochs           : 30\n",
      "Inference time   : 0.083533 seconds\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    preds = model(X_test).detach().cpu().numpy()\n",
    "    end_time = time.time()\n",
    "\n",
    "# Convert predictions to binary (threshold at 0.5 for multi-class, we'll use argmax instead)\n",
    "preds_rounded = np.round(preds).astype(int).flatten()\n",
    "preds_rounded = np.clip(preds_rounded, 0, 2)  # Clip to valid class range\n",
    "\n",
    "# Ensure y_test is integer\n",
    "y_true = y_test.detach().cpu().numpy().astype(int)\n",
    "\n",
    "# Metrics\n",
    "mse = mean_squared_error(y_true, preds.flatten())\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_true, preds.flatten())\n",
    "\n",
    "# For F1-score, we need proper classification predictions\n",
    "try:\n",
    "    f1 = f1_score(y_true, preds_rounded, average='macro')\n",
    "except:\n",
    "    f1 = 0.0  # If F1 calculation fails\n",
    "\n",
    "print(\"\\n--- Evaluation Metrics ---\")\n",
    "print(f\"Noise type       : {noise_type}\")\n",
    "print(f\"Noise strength   : {noise_strength}\")\n",
    "print(f\"Number of qubits : {n_qubits}\")\n",
    "print(f\"MSE              : {mse:.6f}\")\n",
    "print(f\"RMSE             : {rmse:.6f}\")\n",
    "print(f\"MAE              : {mae:.6f}\")\n",
    "print(f\"F1-score         : {f1:.6f}\")\n",
    "print(f\"epochs           : {epochs}\")\n",
    "print(f\"Inference time   : {(end_time - start_time):.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1bee58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
