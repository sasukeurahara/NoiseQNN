{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be97cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cirq\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98329d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== 1. DATA =====\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "mask = y < 2\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)[:, :2]  # use first 2 features\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# ===== 2. CIRCUIT HELPERS =====\n",
    "n_qubits = 2\n",
    "qubits = cirq.LineQubit.range(n_qubits)\n",
    "\n",
    "def build_circuit(params, x):\n",
    "    circuit = cirq.Circuit()\n",
    "    # Feature encoding\n",
    "    for i in range(n_qubits):\n",
    "        circuit.append(cirq.rx(x[i])(qubits[i]))\n",
    "    # Variational layers\n",
    "    for i in range(n_qubits):\n",
    "        circuit.append(cirq.rx(params[i, 0])(qubits[i]))\n",
    "        circuit.append(cirq.rz(params[i, 1])(qubits[i]))\n",
    "    # Entanglement\n",
    "    circuit.append(cirq.CNOT(qubits[0], qubits[1]))\n",
    "    # Measurement\n",
    "    circuit.append(cirq.measure(qubits[0], key=\"m\"))\n",
    "    return circuit\n",
    "\n",
    "def run_circuit(params, x):\n",
    "    sim = cirq.Simulator()\n",
    "    circuit = build_circuit(params, x)\n",
    "    result = sim.run(circuit, repetitions=100)\n",
    "    m = np.mean(result.measurements[\"m\"])\n",
    "    return 1.0 - m  # expectation value mapped to [0,1]\n",
    "\n",
    "# ===== 3. TORCH + PARAMETER-SHIFT =====\n",
    "class CirqFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, params, x):\n",
    "        params_np = params.detach().numpy()\n",
    "        x_np = x.detach().numpy()\n",
    "        out = run_circuit(params_np, x_np)\n",
    "        ctx.save_for_backward(params, x)\n",
    "        return torch.tensor(out, dtype=torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        params, x = ctx.saved_tensors\n",
    "        params_np = params.detach().numpy()\n",
    "        x_np = x.detach().numpy()\n",
    "        shift = np.pi / 2\n",
    "        grads = np.zeros_like(params_np)\n",
    "\n",
    "        for i in range(params_np.shape[0]):\n",
    "            for j in range(params_np.shape[1]):\n",
    "                plus = params_np.copy()\n",
    "                plus[i, j] += shift\n",
    "                minus = params_np.copy()\n",
    "                minus[i, j] -= shift\n",
    "                grad = (run_circuit(plus, x_np) - run_circuit(minus, x_np)) / 2\n",
    "                grads[i, j] = grad\n",
    "\n",
    "        return grad_output * torch.tensor(grads, dtype=torch.float32), None\n",
    "\n",
    "# ===== 4. MODEL =====\n",
    "class QuantumClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.params = nn.Parameter(0.01 * torch.randn(n_qubits, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for xi in x:\n",
    "            outputs.append(CirqFunction.apply(self.params, xi))\n",
    "        return torch.stack(outputs).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556cdd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 4.8035\n",
      "Epoch 2 | Loss: 7.2924\n",
      "Epoch 3 | Loss: 7.2718\n",
      "Epoch 4 | Loss: 5.9862\n",
      "Epoch 5 | Loss: 3.4971\n",
      "Epoch 6 | Loss: 3.3749\n",
      "Epoch 7 | Loss: 4.5429\n",
      "Epoch 8 | Loss: 2.1069\n",
      "Epoch 9 | Loss: 3.2544\n",
      "Epoch 10 | Loss: 3.2270\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== 5. TRAINING =====\n",
    "model = QuantumClassifier()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train.reshape(-1, 1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d736901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Metrics ---\n",
      "MSE: 0.404490\n",
      "RMSE: 0.635995\n",
      "MAE: 0.526000\n",
      "F1-score: 0.538462\n",
      "Inference/sample: 0.001255 sec\n"
     ]
    }
   ],
   "source": [
    "# ===== 6. EVALUATION =====\n",
    "with torch.no_grad():\n",
    "    start_time = time.perf_counter()\n",
    "    preds = model(X_test).numpy()\n",
    "    preds_binary = (preds > 0.5).astype(int)\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    mse = mean_squared_error(y_test, preds.flatten())\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, preds.flatten())\n",
    "    f1 = f1_score(y_test.numpy().astype(int), preds_binary)\n",
    "\n",
    "print(\"\\n--- Metrics ---\")\n",
    "print(f\"MSE: {mse:.6f}\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"MAE: {mae:.6f}\")\n",
    "print(f\"F1-score: {f1:.6f}\")\n",
    "print(f\"Inference/sample: {(end_time - start_time)/len(X_test):.6f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a717023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
